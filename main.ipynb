{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/2HbP3TLr3Q3Pt03C7T6G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Simple LSTM RNN project</h2>\n",
        "<p>The below code is a simple LSTM RNN project</p>"
      ],
      "metadata": {
        "id": "XTbyzX80M2sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "r5BhJlCfNAcn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Collection\n",
        "# Fetch historical stock price data for Apple Inc.\n",
        "ticker = 'AAPL'\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2021-01-01'\n",
        "data = yf.download(ticker, start=start_date, end=end_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufGzJMuRNN2m",
        "outputId": "e42fd2f7-d8c8-4544-cd1f-40a89d7a89e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preprocessing\n",
        "data = data[['Close']]\n",
        "scaler = MinMaxScaler()\n",
        "data['Close'] = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "train_size = int(len(data) * 0.8)\n",
        "train_data = data[:train_size]\n",
        "test_data = data[train_size:]\n",
        "\n",
        "def create_dataset(data, look_back=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:i + look_back])\n",
        "        y.append(data[i + look_back])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "look_back = 30\n",
        "X_train, y_train = create_dataset(train_data.values, look_back)\n",
        "X_test, y_test = create_dataset(test_data.values, look_back)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb6GL3gTNTqj",
        "outputId": "6723dbb8-80a3-45bf-8655-c2bc077f2d65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f3851767cccc>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Close'] = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build the LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "xsJbbVMGNVNC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Model Training\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lugZiT4NWJD",
        "outputId": "6dd03371-1d61-45d2-c96f-357beb8dc726"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "69/69 [==============================] - 6s 33ms/step - loss: 0.0024\n",
            "Epoch 2/50\n",
            "69/69 [==============================] - 4s 52ms/step - loss: 6.1275e-05\n",
            "Epoch 3/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 5.8775e-05\n",
            "Epoch 4/50\n",
            "69/69 [==============================] - 2s 31ms/step - loss: 5.5522e-05\n",
            "Epoch 5/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 5.7323e-05\n",
            "Epoch 6/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 5.4632e-05\n",
            "Epoch 7/50\n",
            "69/69 [==============================] - 3s 49ms/step - loss: 5.5116e-05\n",
            "Epoch 8/50\n",
            "69/69 [==============================] - 3s 36ms/step - loss: 5.0958e-05\n",
            "Epoch 9/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 5.2757e-05\n",
            "Epoch 10/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 4.9371e-05\n",
            "Epoch 11/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 4.7459e-05\n",
            "Epoch 12/50\n",
            "69/69 [==============================] - 4s 62ms/step - loss: 5.0629e-05\n",
            "Epoch 13/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 4.9203e-05\n",
            "Epoch 14/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 4.4633e-05\n",
            "Epoch 15/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 4.5368e-05\n",
            "Epoch 16/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 4.2614e-05\n",
            "Epoch 17/50\n",
            "69/69 [==============================] - 3s 48ms/step - loss: 4.1462e-05\n",
            "Epoch 18/50\n",
            "69/69 [==============================] - 2s 36ms/step - loss: 4.2524e-05\n",
            "Epoch 19/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 3.8260e-05\n",
            "Epoch 20/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 3.4633e-05\n",
            "Epoch 21/50\n",
            "69/69 [==============================] - 2s 35ms/step - loss: 3.9867e-05\n",
            "Epoch 22/50\n",
            "69/69 [==============================] - 3s 48ms/step - loss: 3.8741e-05\n",
            "Epoch 23/50\n",
            "69/69 [==============================] - 3s 36ms/step - loss: 3.4113e-05\n",
            "Epoch 24/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 3.9001e-05\n",
            "Epoch 25/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 3.5897e-05\n",
            "Epoch 26/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 3.4998e-05\n",
            "Epoch 27/50\n",
            "69/69 [==============================] - 3s 44ms/step - loss: 3.3658e-05\n",
            "Epoch 28/50\n",
            "69/69 [==============================] - 3s 40ms/step - loss: 3.1520e-05\n",
            "Epoch 29/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 3.2599e-05\n",
            "Epoch 30/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 3.1239e-05\n",
            "Epoch 31/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 2.7673e-05\n",
            "Epoch 32/50\n",
            "69/69 [==============================] - 3s 40ms/step - loss: 2.7605e-05\n",
            "Epoch 33/50\n",
            "69/69 [==============================] - 3s 45ms/step - loss: 2.6294e-05\n",
            "Epoch 34/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 2.4914e-05\n",
            "Epoch 35/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 2.8755e-05\n",
            "Epoch 36/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 2.5304e-05\n",
            "Epoch 37/50\n",
            "69/69 [==============================] - 3s 39ms/step - loss: 2.7182e-05\n",
            "Epoch 38/50\n",
            "69/69 [==============================] - 3s 49ms/step - loss: 2.4511e-05\n",
            "Epoch 39/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 2.4525e-05\n",
            "Epoch 40/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 2.1945e-05\n",
            "Epoch 41/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 2.6664e-05\n",
            "Epoch 42/50\n",
            "69/69 [==============================] - 2s 35ms/step - loss: 2.1906e-05\n",
            "Epoch 43/50\n",
            "69/69 [==============================] - 3s 49ms/step - loss: 2.3356e-05\n",
            "Epoch 44/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 2.3421e-05\n",
            "Epoch 45/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 1.9968e-05\n",
            "Epoch 46/50\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 2.3903e-05\n",
            "Epoch 47/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 2.1859e-05\n",
            "Epoch 48/50\n",
            "69/69 [==============================] - 3s 51ms/step - loss: 1.9613e-05\n",
            "Epoch 49/50\n",
            "69/69 [==============================] - 2s 34ms/step - loss: 2.4227e-05\n",
            "Epoch 50/50\n",
            "69/69 [==============================] - 2s 33ms/step - loss: 2.0328e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bff0fab5cc0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Model Evaluation\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform the predictions to get original scale\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "train_rmse = np.sqrt(mean_squared_error(train_data[look_back:], train_predict))\n",
        "test_rmse = np.sqrt(mean_squared_error(test_data[look_back:], test_predict))\n",
        "\n",
        "print(f'Training RMSE: {train_rmse}')\n",
        "print(f'Testing RMSE: {test_rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbiABM2RNZxv",
        "outputId": "7111acf7-472e-473e-91c4-c327a16dfab9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 2s 11ms/step\n",
            "17/17 [==============================] - 0s 14ms/step\n",
            "Training RMSE: 27.230700190456073\n",
            "Testing RMSE: 77.06402793435117\n"
          ]
        }
      ]
    }
  ]
}